{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ac738c-a026-4e04-9245-2055d633f690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import csv\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09adc74-4915-4cab-80c6-7285897c087b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that searches for papers using our SQs and returns a list of PubMed IDs\n",
    "def search_pubmed_for_ids(query, max_results=15):\n",
    "    Entrez.email = \"zeynep.korkmaz@tum.de\"  # Set email address\n",
    "\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    return record[\"IdList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316dc3e3-9d81-4c14-b695-375099c17ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_pmc_for_queries(queries, max_results=15):\n",
    "    Entrez.email = \"zeynep.korkmaz@tum.de\"\n",
    "    \n",
    "    handle = Entrez.esearch(db=\"pmc\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    # Return the list of PMCIDs\n",
    "    return record[\"PMCList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b74af3b-96c7-4520-9ee3-c6fd35ebb35c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that reads the keywords and SQs from a directory with CSV files and returns a dictionary\n",
    "def read_keywords_from_directory(directory):\n",
    "    keywords_dict = {}\n",
    "\n",
    "    for filename in os.walk(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            csv_file = os.path.join(directory, filename)\n",
    "            \n",
    "            # for troubleshooting (dictionary only contains 99 files but should contain ~140)\n",
    "            #print(\"Reading keywords from file: {}\".format(csv_file)) # all files are read\n",
    "\n",
    "            with open(csv_file, 'r') as file:\n",
    "                reader = csv.reader(file)\n",
    "\n",
    "                current_pub_title = None\n",
    "                current_keywords = []\n",
    "                current_sq_tp = []\n",
    "                current_sq_fp = []\n",
    "                current_sq_r = []\n",
    "\n",
    "                for row in reader:\n",
    "                    row = [item.strip(', ') for item in row]\n",
    "                    if row and not row[0].isdigit():\n",
    "                        if row[0] == \"Pub Title\":\n",
    "                            if current_pub_title:\n",
    "                                keywords_dict[current_pub_title] = {\n",
    "                                    \"Pub Title\": current_pub_title,\n",
    "                                    \"Keywords\": current_keywords,\n",
    "                                    \"SQ_TP\": current_sq_tp,\n",
    "                                    \"SQ_FP\": current_sq_fp,\n",
    "                                    \"SQ_R\": current_sq_r\n",
    "                                }\n",
    "                            current_pub_title = row[1]\n",
    "                            current_keywords = []\n",
    "                            current_sq_tp = []\n",
    "                            current_sq_fp = []\n",
    "                            current_sq_r = []\n",
    "                        elif row[0] == \"Keywords\":\n",
    "                            current_keywords.extend(item for item in row[1:] if item)\n",
    "                        elif row[0] == \"SQ_TP\":\n",
    "                            current_sq_tp.extend(item for item in row[1:] if item)\n",
    "                        elif row[0] == \"SQ_FP\":\n",
    "                            current_sq_fp.extend(item for item in row[1:] if item)\n",
    "                        elif row[0] == \"SQ_R\":\n",
    "                            current_sq_r.extend(item for item in row[1:] if item)\n",
    "\n",
    "                if current_pub_title:\n",
    "                    keywords_dict[current_pub_title] = {\n",
    "                        \"Pub Title\": current_pub_title,\n",
    "                        \"Keywords\": current_keywords,\n",
    "                        \"SQ_TP\": current_sq_tp,\n",
    "                        \"SQ_FP\": current_sq_fp,\n",
    "                        \"SQ_R\": current_sq_r\n",
    "                    }\n",
    "\n",
    "    return keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb82c44b-4df9-40f4-be49-58a4afd1dcde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that takes keyword_dict/input_dict and returns dict with list of PubMed IDs based on SQs\n",
    "def dict_to_pubmed_id(input_dict):\n",
    "    # Initialize a new dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    # Iterate over each publication entry in the input dictionary\n",
    "    for pub_title, pub_data in input_dict.items():\n",
    "        # Create a copy of the publication data\n",
    "        pub_result = pub_data.copy()\n",
    "\n",
    "        # Initialize empty lists for PubMed IDs for SQ_TP, SQ_FP, and SQ_R\n",
    "        pub_result['PubMed_IDs_TP'] = []\n",
    "        pub_result['PubMed_IDs_FP'] = []\n",
    "        pub_result['PubMed_IDs_R'] = []\n",
    "\n",
    "        # Extract elements from SQ_TP, SQ_FP, and SQ_R lists and search PubMed for IDs\n",
    "        for sq_tp_element in pub_data['SQ_TP']:\n",
    "            pub_result['PubMed_IDs_TP'].extend(search_pubmed_for_ids(sq_tp_element))\n",
    "\n",
    "        for sq_fp_element in pub_data['SQ_FP']:\n",
    "            pub_result['PubMed_IDs_FP'].extend(search_pubmed_for_ids(sq_fp_element))\n",
    "\n",
    "        for sq_r_element in pub_data['SQ_R']:\n",
    "            pub_result['PubMed_IDs_R'].extend(search_pubmed_for_ids(sq_r_element))\n",
    "\n",
    "        # Add the modified publication data to the result dictionary\n",
    "        result_dict[pub_title] = pub_result\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d6a947-239c-4fed-b799-9c4e6ac676dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that takes keyword_dict/input_dict and returns dict with list of PMC IDs based on SQs\n",
    "def dict_to_pmc_id(input_dict):\n",
    "    # Initialize a new dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    # Iterate over each publication entry in the input dictionary\n",
    "    for pub_title, pub_data in input_dict.items():\n",
    "        # Create a copy of the publication data\n",
    "        pub_result = pub_data.copy()\n",
    "\n",
    "        # Initialize empty lists for PubMed IDs for SQ_TP, SQ_FP, and SQ_R\n",
    "        pub_result['PMC_IDs_TP'] = []\n",
    "        pub_result['PMC_IDs_FP'] = []\n",
    "        pub_result['PMC_IDs_R'] = []\n",
    "\n",
    "        # Extract elements from SQ_TP, SQ_FP, and SQ_R lists and search PubMed for IDs\n",
    "        for sq_tp_element in pub_data['SQ_TP']:\n",
    "            pub_result['PMC_IDs_TP'].extend(search_pubmed_for_ids(sq_tp_element))\n",
    "\n",
    "        for sq_fp_element in pub_data['SQ_FP']:\n",
    "            pub_result['PMC_IDs_FP'].extend(search_pubmed_for_ids(sq_fp_element))\n",
    "\n",
    "        for sq_r_element in pub_data['SQ_R']:\n",
    "            pub_result['PMC_IDs_R'].extend(search_pubmed_for_ids(sq_r_element))\n",
    "\n",
    "        # Add the modified publication data to the result dictionary\n",
    "        result_dict[pub_title] = pub_result\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29b0256c-6380-4de2-9d53-7941c0979a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that takes dict with list of PMIDs and PMCIDs for the SQs as input, searches specified directory for the corresping XML papers and combines all to one large XML file (output)\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_xml_files(input_pmid_dict, input_pmc_dict, input_dir, output_file):\n",
    "    \n",
    "    SQ_PMIDs = {\n",
    "        'SQ_TP_PMIDs': [id for pub_title, data in input_pmid_dict.items() for id in data['PubMed_IDs_TP']],\n",
    "        'SQ_FP_PMIDs': [id for pub_title, data in input_pmid_dict.items() for id in data['PubMed_IDs_FP']],\n",
    "        'SQ_R_PMIDs': [id for pub_title, data in input_pmid_dict.items() for id in data['PubMed_IDs_R']]\n",
    "    }\n",
    "    \n",
    "    SQ_PMCIDs = {\n",
    "        'SQ_TP_PMCIDs': [id for pub_title, data in input_pmc_dict.items() for id in data['PMC_IDs_TP']],\n",
    "        'SQ_FP_PMCIDs': [id for pub_title, data in input_pmc_dict.items() for id in data['PMC_IDs_FP']],\n",
    "        'SQ_R_PMCIDs': [id for pub_title, data in input_pmc_dict.items() for id in data['PMC_IDs_R']]\n",
    "    }\n",
    "\n",
    "    with open(output_file, 'wb') as f:\n",
    "        f.write(b'<root>\\n')\n",
    "\n",
    "        for SQ_PMID, SQ_PMCID in zip(SQ_PMIDs.items(), SQ_PMCIDs.items()):\n",
    "            SQ_root = ET.Element(f'{SQ_PMID[0]}_{SQ_PMCID[0]}')\n",
    "\n",
    "            desired_PMID_IDs = SQ_PMID[1]\n",
    "            desired_PMCID_IDs = SQ_PMCID[1]\n",
    "\n",
    "            for root_dir, dirs, files in os.walk(input_dir):\n",
    "                for xml_file in files:\n",
    "                    if xml_file.endswith('.xml'):\n",
    "                        xml_file_path = os.path.join(root_dir, xml_file)\n",
    "\n",
    "                        try:\n",
    "                            tree = ET.parse(xml_file_path)\n",
    "                        except ET.ParseError:\n",
    "                            print(f\"Skipping file due to ParseError: {xml_file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        root = tree.getroot()\n",
    "                        root_copy = copy.deepcopy(root)\n",
    "\n",
    "                        for element in root_copy.iter('article-id'):\n",
    "                            if (\n",
    "                                (element.attrib.get('pub-id-type') == 'pmid' and element.text in desired_PMID_IDs) or\n",
    "                                (element.attrib.get('pub-id-type') == 'pmc' and element.text in desired_PMCID_IDs)\n",
    "                            ):\n",
    "                                SQ_root.append(root_copy)\n",
    "\n",
    "            f.write(ET.tostring(SQ_root, encoding='utf-8'))\n",
    "\n",
    "        f.write(b'</root>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebc98e77-7eea-47e5-9580-f79d3c88e260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Apply workflow:\n",
    "\n",
    "# read dir with CSVs (cannot be nested) and create dict with keywords and SQs\n",
    "csv_input_dir = \"OneDrive/Dokumente/Master_1. Semester/Systems_Biomedicine/Sabrina.csv\" \n",
    "keywords_dict = read_keywords_from_directory(csv_input_dir)\n",
    "\n",
    "# create dict with PubMed IDs for SQs\n",
    "pubmed_id_dict = dict_to_pubmed_id(keywords_dict)\n",
    "\n",
    "# create dict with PubMed IDs for SQs\n",
    "pmc_id_dict = dict_to_pmc_id(keywords_dict)\n",
    "\n",
    "# extract XML files for SQs (xml input dir can be nested)\n",
    "xml_input_dir = \"All_Articles\\\\PMC000xxxxxx\"\n",
    "output_file = \"SQ_improved.xml\"\n",
    "extract_xml_files(pubmed_id_dict, pmc_id_dict, xml_input_dir, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fca986-3b0a-49c0-ad1b-d8e35bb80055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
