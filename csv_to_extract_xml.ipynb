{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ac738c-a026-4e04-9245-2055d633f690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import csv\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd36ca43-38d1-48f2-839a-cf5e8f2c79e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pubmed_csv_to_dict(input_csv):\n",
    "    result_dict = {}\n",
    "\n",
    "    with open(input_csv, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            result_dict[row['Pub Title']] = {\n",
    "                'Pub Title': row['Pub Title'],\n",
    "                'Keywords': [kw.strip() for kw in row['Keywords'].split(',')],\n",
    "                'SQ_TP': [sq.strip() for sq in row['SQ_TP'].split(',')],\n",
    "                'SQ_FP': [sq.strip() for sq in row['SQ_FP'].split(',')],\n",
    "                'SQ_R': [sq.strip() for sq in row['SQ_R'].split(',')],\n",
    "                'PubMed_IDs_TP': [id.strip() for id in row['PubMed_IDs_TP'].split(',')],\n",
    "                'PubMed_IDs_FP': [id.strip() for id in row['PubMed_IDs_FP'].split(',')],\n",
    "                'PubMed_IDs_R': [id.strip() for id in row['PubMed_IDs_R'].split(',')]\n",
    "            }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab4f195-e98a-4f63-97c4-937528f5c9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pmc_csv_to_dict(input_csv):\n",
    "    result_dict = {}\n",
    "\n",
    "    with open(input_csv, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            result_dict[row['Pub Title']] = {\n",
    "                'Pub Title': row['Pub Title'],\n",
    "                'Keywords': [kw.strip() for kw in row['Keywords'].split(',')],\n",
    "                'SQ_TP': [sq.strip() for sq in row['SQ_TP'].split(',')],\n",
    "                'SQ_FP': [sq.strip() for sq in row['SQ_FP'].split(',')],\n",
    "                'SQ_R': [sq.strip() for sq in row['SQ_R'].split(',')],\n",
    "                'PMC_IDs_TP': [id.strip() for id in row['PMC_IDs_TP'].split(',')],\n",
    "                'PMC_IDs_FP': [id.strip() for id in row['PMC_IDs_FP'].split(',')],\n",
    "                'PMC_IDs_R': [id.strip() for id in row['PMC_IDs_R'].split(',')]\n",
    "            }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b0256c-6380-4de2-9d53-7941c0979a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that takes dict with list of PMIDs and PMCIDs for the SQs as input, searches specified directory for the corresping XML papers and combines all to one large XML file (output)\n",
    "def extract_xml_files(input_pmid_dict, input_pmc_dict, input_dir, output_file):\n",
    "    \n",
    "    SQ_PMIDs = {\n",
    "        'SQ_TP_PMIDs': [id for pub_title, data in input_pmid_dict.items() for id in data['PubMed_IDs_TP']],\n",
    "        'SQ_FP_PMIDs': [id for pub_title, data in input_pmid_dict.items() for id in data['PubMed_IDs_FP']],\n",
    "        'SQ_R_PMIDs': [id for pub_title, data in input_pmid_dict.items() for id in data['PubMed_IDs_R']]\n",
    "    }\n",
    "\n",
    "    SQ_PMCIDs = {\n",
    "        'SQ_TP_PMCIDs': [id for pub_title, data in input_pmc_dict.items() for id in data['PMC_IDs_TP']],\n",
    "        'SQ_FP_PMCIDs': [id for pub_title, data in input_pmc_dict.items() for id in data['PMC_IDs_FP']],\n",
    "        'SQ_R_PMCIDs': [id for pub_title, data in input_pmc_dict.items() for id in data['PMC_IDs_R']]\n",
    "    }\n",
    "\n",
    "    with open(output_file, 'wb') as f:\n",
    "        f.write(b'<root>\\n')\n",
    "\n",
    "        for SQ_PMID, SQ_PMCID in zip(SQ_PMIDs.items(), SQ_PMCIDs.items()):\n",
    "            SQ_root = ET.Element(f'{SQ_PMID[0]}_{SQ_PMCID[0]}')\n",
    "\n",
    "            desired_PMID_IDs = SQ_PMID[1]\n",
    "            desired_PMCID_IDs = SQ_PMCID[1]\n",
    "\n",
    "            for root_dir, dirs, files in os.walk(input_dir):\n",
    "                for xml_file in files:\n",
    "                    if xml_file.endswith('.xml'):\n",
    "                        xml_file_path = os.path.join(root_dir, xml_file)\n",
    "\n",
    "                        try:\n",
    "                            tree = ET.parse(xml_file_path)\n",
    "                        except ET.ParseError:\n",
    "                            print(f\"Skipping file due to ParseError: {xml_file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        root = tree.getroot()\n",
    "                        root_copy = copy.deepcopy(root)\n",
    "\n",
    "                        for element in root_copy.iter('article-id'):\n",
    "                            if (\n",
    "                                (element.attrib.get('pub-id-type') == 'pmid' and element.text in desired_PMID_IDs) or\n",
    "                                (element.attrib.get('pub-id-type') == 'pmc' and element.text in desired_PMCID_IDs)\n",
    "                            ):\n",
    "                                SQ_root.append(root_copy)\n",
    "\n",
    "            f.write(ET.tostring(SQ_root, encoding='utf-8'))\n",
    "\n",
    "        f.write(b'</root>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebc98e77-7eea-47e5-9580-f79d3c88e260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_csv = \"PMID_Sabrina.csv\"\n",
    "loaded_pubmed_dict = load_pubmed_csv_to_dict(input_csv)\n",
    "\n",
    "input_csv = \"PMC_Sabrina.csv\"\n",
    "loaded_pmc_dict = load_pmc_csv_to_dict(input_csv)\n",
    "\n",
    "# extract XML files for SQs (xml input dir can be nested)\n",
    "xml_input_dir = \"All_Articles\\\\PMC000xxxxxx\"\n",
    "output_file = \"SQ_Sabrina.xml\"\n",
    "extract_xml_files(loaded_pubmed_dict, loaded_pmc_dict, xml_input_dir, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
